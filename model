import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

# Загрузка данных
data = pd.read_csv("/content/trainee_train.csv")
test_data = pd.read_csv("/content/trainee_test_fish.csv")
test_data = test_data.drop(['Unnamed: 0'], axis=1)

# Разделение данных на признаки (X) и целевую переменную (y)
X = data.drop(["Unnamed: 0", "im"], axis=1)
y = data["im"]

# Разделение на тренировочную, тестовую и валидационную выборки
X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42, stratify=y_val_test)

# Создание моделей для ансамбля
logreg_model = LogisticRegression()
xgb_model = xgb.XGBClassifier()
rf_model = RandomForestClassifier()
gbr_model = GradientBoostingClassifier()

# Создание ансамбля
ensemble_model = VotingClassifier(
    estimators=[('logreg', logreg_model), ('xgb', xgb_model), ('rf', rf_model), ('gbr', gbr_model)],
    voting='soft',
    weights=[1, 1, 1, 1]  # Пример взвешивания моделей (вы можете настроить свои веса)
)

# Обучение ансамбля
ensemble_model.fit(X_train, y_train)

# Предсказание на валидационной выборке без учета параметра scale_pos_weight
y_pred_val = ensemble_model.predict(X_val)

# Вычисление метрик для каждого класса отдельно на валидационной выборке без учета параметра scale_pos_weight
classification_report_val = classification_report(y_val, y_pred_val)
print("Metrics on validation set without adjusting scale_pos_weight:")
print(classification_report_val)

# Поиск оптимального значения scale_pos_weight с использованием кросс-валидации
params = {
    'scale_pos_weight': [1, 5, 10, 20, 50]  # Пример значений для проверки (вы можете настроить свои значения)
}

xgb_optimal_model = xgb.XGBClassifier()

# Кросс-валидация с целью максимизации recall для класса 0
grid_search = GridSearchCV(estimator=xgb_optimal_model, param_grid=params, scoring='recall', cv=5)
grid_search.fit(X_train, y_train)

# Вывод оптимального значения scale_pos_weight
print("Optimal scale_pos_weight:", grid_search.best_params_['scale_pos_weight'])

# Создание оптимальной модели XGBoost с учетом оптимального значения scale_pos_weight
optimal_xgb_model = xgb.XGBClassifier(scale_pos_weight=grid_search.best_params_['scale_pos_weight'])

# Обучение ансамбля с оптимальной моделью XGBoost
ensemble_model.estimators_[1] = ('xgb', optimal_xgb_model)  # Замена модели XGBoost в ансамбле
ensemble_model.fit(X_train, y_train)

# Предсказание на валидационной выборке с учетом оптимального значения scale_pos_weight
y_pred_val_optimal = ensemble_model.predict(X_val)

# Вычисление метрик для каждого класса отдельно на валидационной выборке с учетом оптимального значения scale_pos_weight
classification_report_val_optimal = classification_report(y_val, y_pred_val_optimal)
print("Metrics on validation set with optimal scale_pos_weight:")
print(classification_report_val_optimal)

# Предсказание на тестовой выборке с учетом оптимального значения scale_pos_weight
y_pred_test_optimal = ensemble_model.predict(X_test)

# Вычисление метрик для каждого класса отдельно на тестовой выборке с учетом оптимального значения scale_pos_weight

classification_report_test_optimal = classification_report(y_test, y_pred_test_optimal)
print("Metrics on test set with optimal scale_pos_weight:")
print(classification_report_test_optimal)

# Вычисление accuracy на тестовой выборке с учетом оптимального значения scale_pos_weight
accuracy_test_optimal = accuracy_score(y_test, y_pred_test_optimal)
print("Accuracy on test set with optimal scale_pos_weight:", accuracy_test_optimal)

# Вычисление площади под ROC-кривой на тестовой выборке с учетом оптимального значения scale_pos_weight
y_pred_proba_test_optimal = ensemble_model.predict_proba(X_test)[:, 1]
roc_auc_test_optimal = roc_auc_score(y_test, y_pred_proba_test_optimal)
print("Area under ROC curve on test set with optimal scale_pos_weight:", roc_auc_test_optimal)

pred_file = ensemble_model.predict(test_data)
# Создание DataFrame с предсказаниями
predictions = pd.DataFrame({'Prediction': pred_file})

# Сохранение предсказаний в CSV файл
predictions.to_csv('/content/test_predictions_ensemble3.csv', index=False)

# Скачивание файла из Google Colab
from google.colab import files
files.download('/content/test_predictions_ensemble3.csv')
